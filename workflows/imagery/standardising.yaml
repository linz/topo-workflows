---
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: imagery-standardising-v0.2.0-48
  namespace: argo
spec:
  parallelism: 20
  nodeSelector:
    karpenter.sh/capacity-type: "spot"
  entrypoint: main
  arguments:
    parameters:
      - name: source
        value: "s3://linz-imagery-staging/test/sample/"
      - name: include
        value: ".tiff?$"
      - name: group
        value: "10"
      - name: compression
        value: "webp"
        enum:
          - "webp"
          - "lzw"
          - "gray_webp"
      - name: start_datetime
        value: "YYYY-MM-DD"
      - name: end_datetime
        value: "YYYY-MM-DD"
  templates:
    - name: main
      dag:
        tasks:
          - name: aws-list
            template: aws-list
          - name: generate-ulid
            template: generate-ulid
          - name: standardise-validate
            template: standardise-validate
            arguments:
              parameters:
                - name: file
                  value: "{{item}}"
                - name: collection_id
                  value: "{{tasks.generate-ulid.outputs.parameters.ulid}}"
            depends: "aws-list && generate-ulid"
            withParam: "{{tasks.aws-list.outputs.parameters.files}}"
          - name: get-location
            template: get-location
          - name: create-config
            arguments:
              parameters:
                - name: location
                  value: "{{tasks.get-location.outputs.parameters.location}}"
            template: create-config
            depends: "get-location && standardise-validate"
    - name: aws-list
      container:
        image: ghcr.io/linz/argo-tasks:v1.0.0-23-gea36c2f
        command: [node, /app/index.cjs]
        env:
          - name: AWS_ROLE_CONFIG_PATH
            value: s3://linz-bucket-config/config-v2.json
        args:
          [
            "list",
            "--verbose",
            "--include",
            "{{workflow.parameters.include}}",
            "--group",
            "{{workflow.parameters.group}}",
            "--output",
            "/tmp/file_list.json",
            "{{workflow.parameters.source}}",
          ]
      outputs:
        parameters:
          - name: files
            valueFrom:
              path: /tmp/file_list.json
    - name: generate-ulid
      script:
        image: ghcr.io/linz/topo-imagery:v0.2.0-48-g20f5f34
        command: [python]
        source: |
          import ulid
          with open("/tmp/ulid", "w") as f:
            f.write(str(ulid.ULID()))
      outputs:
        parameters:
          - name: ulid
            valueFrom:
              path: "/tmp/ulid"
    - name: standardise-validate
      retryStrategy:
        limit: "2"
      nodeSelector:
        karpenter.sh/capacity-type: "spot"
      inputs:
        parameters:
          - name: file
          - name: collection_id
      container:
        image: ghcr.io/linz/topo-imagery:v0.2.0-48-g20f5f34
        resources:
          requests:
            memory: 7.8Gi
            cpu: 2000m
            ephemeral-storage: 3Gi
        volumeMounts:
          - name: ephemeral
            mountPath: "/tmp"
        command:
          - python
          - "/app/scripts/standardise_validate.py"
        args:
          - "--source"
          - "{{inputs.parameters.file}}"
          - "--preset"
          - "{{workflow.parameters.compression}}"
          - "--start_datetime"
          - "{{workflow.parameters.start_datetime}}"
          - "--end_datetime"
          - "{{workflow.parameters.end_datetime}}"
          - "--collection_id"
          - "{{inputs.parameters.collection_id}}"
      outputs:
        artifacts:
          - name: standardised_tiffs
            path: /tmp/
            archive:
              none: {}
    - name: get-location
      script:
        image: node:alpine
        command: [node]
        source: |
          const fs = require('fs');
          const loc = JSON.parse(process.env['ARGO_TEMPLATE']).archiveLocation.s3;
          const key = loc.key.replace('{{pod.name}}','');
          fs.writeFileSync('/tmp/location', `s3://${loc.bucket}/${key}`);
      outputs:
        parameters:
          - name: location
            valueFrom:
              path: "/tmp/location"
    - name: create-config
      inputs:
        parameters:
          - name: location
      container:
        image: ghcr.io/linz/basemaps/cli:v6.34.0-27-gd3c9adb8
        command: [node, index.cjs]
        env:
          - name: AWS_ROLE_CONFIG_PATH
            value: s3://linz-bucket-config/config.json
        args:
          [
            "-V",
            "create-config",
            "--path",
            "{{inputs.parameters.location}}",
            "--output",
            "/tmp/url",
            "--commit",
          ]
      outputs:
        parameters:
          - name: url
            valueFrom:
              path: "/tmp/url"
  volumes:
    - name: ephemeral
      emptyDir: {}
