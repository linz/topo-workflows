# yaml-language-server: $schema=https://raw.githubusercontent.com/argoproj/argo-workflows/v3.6.12/api/jsonschema/schema.json

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: unarchive
spec:
  nodeSelector:
    karpenter.sh/capacity-type: 'spot'
  entrypoint: main
  onExit: exit-handler
  workflowMetadata:
    labelsFrom:
      linz.govt.nz/user-group:
        expression: workflow.parameters.user_group
      linz.govt.nz/ticket:
        expression: workflow.parameters.ticket
  podMetadata:
    labels:
      linz.govt.nz/user-group: '{{workflow.parameters.user_group}}'
      linz.govt.nz/ticket: '{{workflow.parameters.ticket}}'
  arguments:
    parameters:
      - name: version_argo_tasks
        description: 'Specify a version of the argo-tasks image to use, e.g. "v5.1" or "latest"'
        value: 'v5'
      - name: user_group
        description: Group of users running the workflow
        value: 'none'
        enum:
          - 'land'
          - 'sea'
          - 'none'
      - name: ticket
        description: 'Ticket ID, e.g. "LI-1570"'
        value: ''
      - name: archive_bucket
        description: 'The S3 bucket where the data to unarchive is stored.'
        value: 'linz-hydrographic-archive'
        enum:
          - 'linz-topographic-archive'
          - 'linz-hydrographic-archive'
      - name: archive_directory
        description: 'The directory in the archive bucket where the data to unarchive is stored. Does not include the bucket name. Example: "aerialsurveys/Invercargill2022_Pgrm3016/".'
        value: ''
      - name: consumer
        description: 'The consumer for who the data is being unarchived. The unarchive data will be copied to the consumer shared location.'
        value: 'linz'
        enum:
          - 'linz'
      - name: urgent
        description: 'Whether the unarchive request is urgent (with a cost impact). If not urgent ("BULK" retrieval tier), the restore process can take up to 48 hours. If urgent ("STANDARD" retrieval tier), it will take up to 12 hours. Defaults to false.'
        value: 'false'
        enum:
          - 'true'
          - 'false'
      - name: group
        description: 'Number of files to include in each manifest group for the restore request.'
        value: '1000'
      - name: group_size
        description: 'Maximum size (in MB) of each manifest group for the restore request.'
        value: '100Gi'
  templates:
    - name: main
      dag:
        tasks:
          - name: get-location
            templateRef:
              name: tpl-get-location
              template: main
            arguments:
              parameters:
                - name: version_argo_tasks
                  value: '{{workflow.parameters.version_argo_tasks}}'
          - name: create-manifest
            templateRef:
              name: tpl-create-manifest
              template: main
            arguments:
              parameters:
                - name: source
                  value: 's3://{{workflow.parameters.archive_bucket}}/{{=sprig.trimPrefix("/",workflow.parameters.archive_directory)}}'
                - name: target
                  value: 's3://{{= workflow.parameters.archive_bucket == "linz-topographic-archive" ? "linz-topographic-shared" : workflow.parameters.archive_bucket == "linz-hydrographic-archive" ? "linz-hydrographic-shared" : "unknown-bucket" }}/{{workflow.parameters.consumer}}/{{=sprig.trimPrefix("/",workflow.parameters.archive_directory)}}'
                - name: action_location
                  value: '{{=sprig.trimSuffix("/", tasks["get-location"].outputs.parameters.location)}}/actions/'
                - name: include
                  value: '.*'
                - name: group
                  value: '{{workflow.parameters.group}}'
                - name: group_size
                  value: '{{workflow.parameters.group_size}}'
                - name: aws_role_config_path
                  value: 's3://linz-bucket-config/config-write.topographic.json, s3://linz-bucket-config/config-write.hydrographic.json'
            depends: 'get-location.Succeeded'
          - name: restore
            template: restore
            arguments:
              parameters:
                - name: archive_bucket
                  value: '{{workflow.parameters.archive_bucket}}'
                - name: archive_directory
                  value: '{{=sprig.trimSuffix("/",sprig.trimPrefix("/",workflow.parameters.archive_directory))}}'
                - name: archive_path
                  value: '{{workflow.parameters.archive_bucket}}/{{=sprig.trimSuffix("/",sprig.trimPrefix("/",sprig.trim(workflow.parameters.archive_directory)))}}'
                - name: retrieval_tier
                  value: '{{= workflow.parameters.urgent == "true" ? "STANDARD" : "BULK"}}'
                - name: manifest_list
                  value: '{{tasks.create-manifest.outputs.parameters.files}}'
                - name: request_output_bucket
                  value: '{{tasks.get-location.outputs.parameters.bucket}}'
                - name: restore_location
                  value: 's3://{{= workflow.parameters.archive_bucket == "linz-topographic-archive" ? "linz-topographic-shared" : workflow.parameters.archive_bucket == "linz-hydrographic-archive" ? "linz-hydrographic-shared" : "unknown-bucket" }}/{{workflow.parameters.consumer}}/{{=sprig.trimPrefix("/",workflow.parameters.archive_directory)}}'
                - name: consumer
                  value: '{{workflow.parameters.consumer}}'
            depends: 'get-location && create-manifest'
            when: '{{tasks.create-manifest.outputs.parameters.files}} != ""'

    - name: restore
      inputs:
        parameters:
          - name: archive_bucket
          - name: archive_directory
          - name: archive_path
          - name: retrieval_tier
          - name: manifest_list
          - name: request_output_bucket
          - name: restore_location
          - name: consumer
      container:
        image: public.ecr.aws/aws-cli/aws-cli:2.27.62
        env:
          - name: ACCOUNT_ID_HYDRO
            valueFrom:
              secretKeyRef:
                key: ACCOUNT_ID_HYDRO
                name: s3-batch-restore-secrets
          - name: ACCOUNT_ID_TOPO
            valueFrom:
              secretKeyRef:
                key: ACCOUNT_ID_TOPO
                name: s3-batch-restore-secrets
          - name: ROLE_ARN
            valueFrom:
              secretKeyRef:
                key: ROLE_ARN
                name: s3-batch-restore-secrets
        command: [sh, -c]
        args:
          - |
            # Determine the account ID for the archive bucket
            if [ "{{inputs.parameters.archive_bucket}}" = "linz-hydrographic-archive" ]; then
              ACCOUNT_ID_ARCHIVE=$ACCOUNT_ID_HYDRO
            elif [ "{{inputs.parameters.archive_bucket}}" = "linz-topographic-archive" ]; then
              ACCOUNT_ID_ARCHIVE=$ACCOUNT_ID_TOPO
            else
              echo "Unknown archive bucket: {{inputs.parameters.archive_bucket}}" >&2
              exit 1
            fi

            # Save the list of copy action manifests to local for artifact output
            echo '{{inputs.parameters.manifest_list}}' > /tmp/copy-manifests.json

            TODAY_YYYY_MM=$(date +%Y-%m)
            TODAY_DD=$(date +%d)
            REQUEST_LOCATION="{{inputs.parameters.archive_path}}/${TODAY_YYYY_MM}/${TODAY_DD}-{{workflow.name}}"

            JOB_ID=$(aws s3control create-job \
              --client-request-token "restore-job-{{workflow.name}}" \
              --account-id "$ACCOUNT_ID_TOPO" \
              --region ap-southeast-2 \
              --operation '{
                "S3InitiateRestoreObject": {
                  "ExpirationInDays": 2,
                  "GlacierJobTier": "{{inputs.parameters.retrieval_tier}}"
                }
              }' \
              --report "{
                \"Bucket\": \"arn:aws:s3:::{{inputs.parameters.request_output_bucket}}\",
                \"Format\": \"Report_CSV_20180820\",
                \"Enabled\": true,
                \"Prefix\": \"restore/requests/${REQUEST_LOCATION}\",
                \"ReportScope\": \"AllTasks\"
              }" \
              --manifest-generator "{
                \"S3JobManifestGenerator\": {
                  \"ExpectedBucketOwner\": \"$ACCOUNT_ID_ARCHIVE\",
                  \"SourceBucket\": \"arn:aws:s3:::{{inputs.parameters.archive_bucket}}\",
                  \"ManifestOutputLocation\": {
                    \"ExpectedManifestBucketOwner\": \"$ACCOUNT_ID_TOPO\",
                    \"Bucket\": \"arn:aws:s3:::{{inputs.parameters.request_output_bucket}}\",
                    \"ManifestPrefix\": \"restore/manifests/${REQUEST_LOCATION}\",
                    \"ManifestFormat\": \"S3InventoryReport_CSV_20211130\"
                  },
                  \"Filter\": {
                    \"KeyNameConstraint\": {
                      \"MatchAnyPrefix\": [\"{{inputs.parameters.archive_directory}}/\"]
                    },
                    \"MatchAnyStorageClass\": [\"DEEP_ARCHIVE\"]
                  },
                  \"EnableManifestOutput\": true
                }
              }" \
              --priority 10 \
              --role-arn "$ROLE_ARN" \
              --description "{{workflow.name}}" \
              --debug \
              --no-confirmation-required \
              --query 'JobId' \
              --output text)

            # Check if JOB_ID is empty
            if [ -z "$JOB_ID" ]; then
              echo "Error: Failed to create restore job." >&2
              exit 1
            fi

            # Upload the copy manifests list at the same location as the report manifest
            aws s3 cp /tmp/copy-manifests.json "s3://{{inputs.parameters.request_output_bucket}}/restore/requests/${REQUEST_LOCATION}/job-${JOB_ID}/copy-manifests.json"

            # Store information for Slack alerting and upload to the same location as copy and restore manifests
            jq -nc '
              [
                {name: "restore_location", value: "{{inputs.parameters.restore_location}}"},
                {name: "archive_bucket", value: "s3://{{inputs.parameters.archive_bucket}}"},
                {name: "consumer", value: "{{inputs.parameters.consumer}}"}
              ]
            ' > /tmp/restore-details
            aws s3 cp /tmp/restore-details "s3://{{inputs.parameters.request_output_bucket}}/restore/requests/${REQUEST_LOCATION}/job-${JOB_ID}/restore-details"

    - name: exit-handler
      retryStrategy:
        limit: '0' # `tpl-log-notification` retries itself
      steps:
        - - name: exit
            templateRef:
              name: tpl-log-notification
              template: main
            arguments:
              parameters:
                - name: workflow_status
                  value: '{{workflow.status}}'
                - name: workflow_parameters
                  value: '{{workflow.parameters}}'
